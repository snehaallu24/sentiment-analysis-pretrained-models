{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Sentiment Analysis using Pre-trained BERT\n"
      ],
      "metadata": {
        "id": "FOJ4BCDMsokE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1: Install necessary libraries\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install torch\n"
      ],
      "metadata": {
        "id": "EfMR9rEsnrKD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 2: Import required libraries\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, TextClassificationPipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import files\n",
        "import zipfile\n"
      ],
      "metadata": {
        "id": "k9v1Bv_PnxcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 3: Upload and read dataset (must be Tweets_sampled.csv or a zip containing it)\n",
        "uploaded = files.upload()\n",
        "\n",
        "# If it's a zip file, extract it\n",
        "for fn in uploaded.keys():\n",
        "    if fn.endswith(\".zip\"):\n",
        "        with zipfile.ZipFile(fn, 'r') as zip_ref:\n",
        "            zip_ref.extractall(\".\")\n"
      ],
      "metadata": {
        "id": "OahF_82mnyOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 4: Load CSV\n",
        "df = pd.read_csv(\"Tweets_sampled.csv\")\n",
        "df = df.rename(columns={\"airline_sentiment\": \"label\", \"text\": \"text\"})\n",
        "df = df[[\"text\", \"label\"]]"
      ],
      "metadata": {
        "id": "o7nGrQPjnyR7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 5: Preprocess Labels\n",
        "label_map = {\"positive\": 2, \"neutral\": 1, \"negative\": 0}\n",
        "df[\"label\"] = df[\"label\"].map(label_map)"
      ],
      "metadata": {
        "id": "NIYys-6onyYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 6: Train-test split\n",
        "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
        "    df[\"text\"].tolist(), df[\"label\"].tolist(), test_size=0.2, random_state=42\n",
        ")\n"
      ],
      "metadata": {
        "id": "rnM-mOg8nybS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# STEP 7: Load tokenizer and model\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=3)\n"
      ],
      "metadata": {
        "id": "z_WYqMF7nyeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 8: Tokenize data\n",
        "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n",
        "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=128)\n"
      ],
      "metadata": {
        "id": "K0WKFA6jnygU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 9: Prepare Dataset\n",
        "class SimpleDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = SimpleDataset(train_encodings, train_labels)\n",
        "test_dataset = SimpleDataset(test_encodings, test_labels)"
      ],
      "metadata": {
        "id": "kZrq5hm7nyju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 10: Training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    do_eval=True,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=10,\n",
        "    save_strategy=\"no\",\n",
        "    report_to=\"none\"  # disables wandb\n",
        ")\n"
      ],
      "metadata": {
        "id": "0qCeSd6Znyw4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# STEP 11: Train the model\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "id": "wLVx716roaVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 12: Inference with a few sample texts\n",
        "pipe = TextClassificationPipeline(model=model, tokenizer=tokenizer, return_all_scores=False, device=0 if torch.cuda.is_available() else -1)\n",
        "\n",
        "examples = [\n",
        "    \"I absolutely loved the flight service!\",\n",
        "    \"This airline is terrible, I want a refund!\",\n",
        "    \"The flight was delayed, but it was okay overall.\"\n",
        "]\n",
        "\n",
        "for text in examples:\n",
        "    result = pipe(text)[0]\n",
        "    print(f\"Text: '{text}' â†’ Predicted Sentiment: {result['label']}, Score: {round(result['score'], 2)}\")\n"
      ],
      "metadata": {
        "id": "iiPejqRooaZL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}